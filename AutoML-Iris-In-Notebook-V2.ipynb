{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Experiment, Run, Workspace\nimport azureml.core\n\n# Check core SDK version number\nprint(\"SDK version:\", azureml.core.VERSION)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "SDK version: 1.0.17\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "subscription_id = '6a0ec27b-1111-1111-1111-8c3003d5e4bc'\nresource_group  = 'PythonSDK'\nworkspace_name  = 'pythonsdkworkspace'\n\ntry:\n    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n    ws.write_config()\n    print('Library configuration succeeded')\nexcept:\n    print('Workspace not found')\n",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Wrote the config file config.json to: /home/nbuser/library/aml_config/config.json\nLibrary configuration succeeded\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "experiment_name = 'autoMLdemo1'",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.externals import joblib\nfrom sklearn.datasets import load_iris\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\nirisds = load_iris()\n\niris = sns.load_dataset(\"iris\")\ntype(iris)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "pandas.core.frame.DataFrame"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y = iris.species\nX = iris.drop('species',axis=1)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.3, \n                                                    random_state=100, \n                                                    stratify=y)\n",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Create a function to convert species to numeric\ndef func(x):\n     if x == 'setosa':\n          return 1\n     elif x == 'versicolor':\n          return 2\n     elif x == 'virginica':\n          return 3\n\nfrom numpy import vectorize\nvfunc = vectorize(func) #Define a vectorized function which takes a nested sequence of objects or numpy arrays as inputs\n\nyfactTrain = vfunc(y_train)\nyfactTest = vfunc(y_test)\n\nyfactTrain = yfactTrain.reshape(len(yfactTrain))\nyfactTest = yfactTest.reshape(len(yfactTest))\n",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train = X_train.astype(np.float)\nX_test = X_test.astype(np.float)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "yfactTrain",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "array([2, 2, 1, 1, 1, 3, 3, 2, 3, 3, 1, 1, 3, 3, 1, 2, 2, 3, 3, 2, 2, 1,\n       3, 3, 3, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 3, 1, 3, 2, 2, 3, 2, 2, 3,\n       3, 2, 1, 3, 2, 1, 2, 3, 3, 2, 2, 3, 1, 2, 2, 1, 2, 2, 2, 3, 1, 1,\n       3, 1, 1, 1, 3, 2, 3, 3, 1, 2, 3, 1, 3, 2, 1, 1, 1, 2, 1, 2, 1, 1,\n       1, 1, 3, 3, 3, 3, 3, 2, 1, 3, 2, 1, 1, 2, 3, 2, 3])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>71</th>\n      <td>6.1</td>\n      <td>2.8</td>\n      <td>4.0</td>\n      <td>1.3</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>5.5</td>\n      <td>2.6</td>\n      <td>4.4</td>\n      <td>1.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>5.7</td>\n      <td>3.8</td>\n      <td>1.7</td>\n      <td>0.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "    sepal_length  sepal_width  petal_length  petal_width\n71           6.1          2.8           4.0          1.3\n90           5.5          2.6           4.4          1.2\n4            5.0          3.6           1.4          0.2\n17           5.1          3.5           1.4          0.3\n18           5.7          3.8           1.7          0.3"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.train.automl import AutoMLConfig\nfrom azureml.train.automl.constants import Metric\n\n##Local compute \nAutoml_config = AutoMLConfig(task = 'classification',\n                             primary_metric = Metric.Accuracy,\n                             #primary_metric = Metric.AUCWeighted,\n                             iteration_timeout_minutes = 12000,\n                             iterations = 6,\n                             #n_cross_validations = 2,\n                             preprocess = False,\n                             #exit_score = 0.995,\n                             #blacklist_models = ['kNN','LinearSVM'],\n                             enable_onnx_compatible_models=True,\n                             X = X_train,\n                             y = yfactTrain,\n                             X_valid = X_test,\n                             y_valid = yfactTest,\n                             path='./sample_projects/automl-local-classification')",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.experiment import Experiment\nexperiment=Experiment(ws, experiment_name)\nlocal_run = experiment.submit(Automl_config, show_output=True)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "WARNING:root:Received unrecognized parameter: enable_onnx_compatible_models True\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Running on local machine\nParent Run ID: AutoML_5f8b2b50-d03a-4b84-b5d9-e39d87d0486d\n********************************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nSAMPLING %: Percent of the training data to sample.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************************************\n\n ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n         0   StandardScalerWrapper LightGBM                 100.0000    0:00:20       0.9333    0.9333\n         1   MaxAbsScaler LightGBM                          100.0000    0:00:11       0.9333    0.9333\n         2   MinMaxScaler LightGBM                          100.0000    0:00:10       0.9111    0.9333\n         3   StandardScalerWrapper LightGBM                 100.0000    0:00:11       0.9111    0.9333\n         4   StandardScalerWrapper LightGBM                 100.0000    0:00:11       0.9333    0.9333\n         5   Ensemble                                       100.0000    0:00:18       0.9333    0.9333\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(local_run).show()",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4e43c33af454623b76aa735be2994e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 's…"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20c66b152dfc4715a81631404b7b6e09",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Breakdown of the results\nchildren = list(local_run.get_children())\nmetricslist = {}\nfor run in children:\n    properties = run.get_properties()\n    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n    metricslist[int(properties['iteration'])] = metrics\n\nimport pandas as pd\nrundata = pd.DataFrame(metricslist).sort_index(1)\nrundata",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AUC_macro</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.97</td>\n      <td>0.99</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>AUC_micro</th>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.97</td>\n      <td>0.99</td>\n      <td>0.96</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>AUC_weighted</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.97</td>\n      <td>0.99</td>\n      <td>0.97</td>\n      <td>0.97</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.93</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>average_precision_score_macro</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.94</td>\n      <td>0.99</td>\n      <td>0.93</td>\n      <td>0.94</td>\n    </tr>\n    <tr>\n      <th>average_precision_score_micro</th>\n      <td>0.99</td>\n      <td>0.99</td>\n      <td>0.95</td>\n      <td>0.97</td>\n      <td>0.90</td>\n      <td>0.94</td>\n    </tr>\n    <tr>\n      <th>average_precision_score_weighted</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.94</td>\n      <td>0.99</td>\n      <td>0.93</td>\n      <td>0.94</td>\n    </tr>\n    <tr>\n      <th>balanced_accuracy</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.93</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>f1_score_macro</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.93</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>f1_score_micro</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.93</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>f1_score_weighted</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.93</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>log_loss</th>\n      <td>1.90</td>\n      <td>1.71</td>\n      <td>1.14</td>\n      <td>2.50</td>\n      <td>1.82</td>\n      <td>1.64</td>\n    </tr>\n    <tr>\n      <th>norm_macro_recall</th>\n      <td>0.90</td>\n      <td>0.90</td>\n      <td>0.87</td>\n      <td>0.87</td>\n      <td>0.90</td>\n      <td>0.90</td>\n    </tr>\n    <tr>\n      <th>precision_score_macro</th>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.94</td>\n      <td>0.94</td>\n    </tr>\n    <tr>\n      <th>precision_score_micro</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.93</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>precision_score_weighted</th>\n      <td>0.94</td>\n      <td>0.94</td>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.94</td>\n      <td>0.94</td>\n    </tr>\n    <tr>\n      <th>recall_score_macro</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.93</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>recall_score_micro</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.93</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>recall_score_weighted</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.93</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>weighted_accuracy</th>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.93</td>\n      <td>0.93</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                    0    1    2    3    4    5\nAUC_macro                        1.00 1.00 0.97 0.99 0.97 0.97\nAUC_micro                        0.99 0.99 0.97 0.99 0.96 0.97\nAUC_weighted                     1.00 1.00 0.97 0.99 0.97 0.97\naccuracy                         0.93 0.93 0.91 0.91 0.93 0.93\naverage_precision_score_macro    1.00 1.00 0.94 0.99 0.93 0.94\naverage_precision_score_micro    0.99 0.99 0.95 0.97 0.90 0.94\naverage_precision_score_weighted 1.00 1.00 0.94 0.99 0.93 0.94\nbalanced_accuracy                0.93 0.93 0.91 0.91 0.93 0.93\nf1_score_macro                   0.93 0.93 0.91 0.91 0.93 0.93\nf1_score_micro                   0.93 0.93 0.91 0.91 0.93 0.93\nf1_score_weighted                0.93 0.93 0.91 0.91 0.93 0.93\nlog_loss                         1.90 1.71 1.14 2.50 1.82 1.64\nnorm_macro_recall                0.90 0.90 0.87 0.87 0.90 0.90\nprecision_score_macro            0.94 0.94 0.93 0.93 0.94 0.94\nprecision_score_micro            0.93 0.93 0.91 0.91 0.93 0.93\nprecision_score_weighted         0.94 0.94 0.93 0.93 0.94 0.94\nrecall_score_macro               0.93 0.93 0.91 0.91 0.93 0.93\nrecall_score_micro               0.93 0.93 0.91 0.91 0.93 0.93\nrecall_score_weighted            0.93 0.93 0.91 0.91 0.93 0.93\nweighted_accuracy                0.93 0.93 0.91 0.91 0.93 0.93"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Get the best model\nbest_run, fitted_model = local_run.get_output()\n",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "WARNING:root:Received unrecognized parameter: enable_onnx_compatible_models True\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>autoMLdemo1</td><td>AutoML_5f8b2b50-d03a-4b84-b5d9-e39d87d0486d_5</td><td></td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/6a0ec27b-1203-46fe-ade0-8c3003d5e4bc/resourceGroups/PythonSDK/providers/Microsoft.MachineLearningServices/workspaces/pythonsdkworkspace/experiments/autoMLdemo1/runs/AutoML_5f8b2b50-d03a-4b84-b5d9-e39d87d0486d_5\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>",
            "text/plain": "Run(Experiment: autoMLdemo1,\nId: AutoML_5f8b2b50-d03a-4b84-b5d9-e39d87d0486d_5,\nType: None,\nStatus: Completed)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Test with the testing data\n\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\n\ny_pred = (fitted_model.predict(X_test))\n\nprint(accuracy_score(yfactTest, y_pred))\n\ncm = confusion_matrix(yfactTest, y_pred)\nprint(cm)\n",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.9333333333333333\n[[15  0  0]\n [ 0 15  0]\n [ 0  3 12]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.compute import AmlCompute\nfrom azureml.core.compute import ComputeTarget\n\n# Choose a name for your cluster.\namlcompute_cluster_name = \"automlcl\"\n\nfound = False\n# Check if this compute target already exists in the workspace.\ncts = ws.compute_targets\nif amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n    found = True\n    print('Found existing compute target.')\n    compute_target = cts[amlcompute_cluster_name]\n    \nif not found:\n    print('Creating a new compute target...')\n    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\", # for GPU, use \"STANDARD_NC6\"\n                                                                #vm_priority = 'lowpriority', # optional\n                                                                min_nodes = 0, max_nodes = 6)\n\n    # Create the cluster.\n    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n    \n    # Can poll for a minimum number of nodes and for a specific timeout.\n    # If no min_node_count is provided, it will use the scale settings for the cluster.\n    compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n    \n     # For a more detailed view of current AmlCompute status, use get_status().",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found existing compute target.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import datasets\nimport os\nimport csv\n\n\nif not os.path.isdir('AMLdata'):\n    os.mkdir('AMLdata')\n    \npd.DataFrame(X_train).to_csv(\"AMLdata/X_train.tsv\", index=False, header=False, quoting=csv.QUOTE_ALL, sep=\"\\t\")\npd.DataFrame(y_train).to_csv(\"AMLdata/y_train.tsv\", index=False, header=False, sep=\"\\t\")\n\nds = ws.get_default_datastore()\nds.upload(src_dir='./AMLdata', target_path='bai_data', overwrite=True, show_progress=True)\n\nfrom azureml.core.runconfig import DataReferenceConfiguration\ndr = DataReferenceConfiguration(datastore_name=ds.name, \n                   path_on_datastore='bai_data', \n                   path_on_compute='/tmp/azureml_runs',\n                   mode='download', # download files from datastore to compute target\n                   overwrite=False)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Uploading ./AMLdata/y_train.tsv\nUploading ./AMLdata/X_train.tsv\nUploading ./AMLdata/__pycache__/get_data.cpython-36.pyc\nUploaded ./AMLdata/y_train.tsv, 1 files out of an estimated total of 3\nUploaded ./AMLdata/X_train.tsv, 2 files out of an estimated total of 3\nUploaded ./AMLdata/__pycache__/get_data.cpython-36.pyc, 3 files out of an estimated total of 3\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.runconfig import RunConfiguration\nfrom azureml.core.conda_dependencies import CondaDependencies\n\n# create a new RunConfig object\nconda_run_config = RunConfiguration(framework=\"python\")\n\n# Set compute target to AmlCompute\nconda_run_config.target = compute_target\nconda_run_config.environment.docker.enabled = True\nconda_run_config.environment.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE\n\n# set the data reference of the run coonfiguration\nconda_run_config.data_references = {ds.name: dr}\n\ncd = CondaDependencies.create(pip_packages=['azureml-sdk[automl]'], conda_packages=['numpy','py-xgboost<=0.80'])\nconda_run_config.environment.python.conda_dependencies = cd",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "project_folder = './project'\n\nif not os.path.exists(project_folder):\n    os.makedirs(project_folder)",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile $project_folder/get_data.py\n\nimport pandas as pd\n\ndef get_data():\n    X_train = pd.read_csv(\"/tmp/azureml_runs/bai_data/X_train.tsv\", delimiter=\"\\t\", header=None, quotechar='\"')\n    y_train = pd.read_csv(\"/tmp/azureml_runs/bai_data/y_train.tsv\", delimiter=\"\\t\", header=None, quotechar='\"')\n\n    return { \"X\" : X_train.values, \"y\" : y_train[0].values }",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting ./project/get_data.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import logging\n\nautoml_settings = {\n    \"iteration_timeout_minutes\": 10,\n    \"iterations\": 20,\n    \"n_cross_validations\": 5,\n    \"primary_metric\": 'AUC_weighted',\n    \"preprocess\": False,\n    \"max_concurrent_iterations\": 5,\n    \"verbosity\": logging.INFO\n}\n\nautoml_config = AutoMLConfig(task = 'classification',\n                             debug_log = 'automl_errors.log',\n                             path = project_folder,\n                             run_configuration=conda_run_config,\n                             data_script = project_folder + \"/get_data.py\",\n                             **automl_settings\n                            )",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "remote_run = experiment.submit(automl_config, show_output = False)",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "remote_run",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>autoMLdemo1</td><td>AutoML_84c472b3-a9af-4e84-b3cf-25c062742f5b</td><td>automl</td><td>Preparing</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/6a0ec27b-1203-46fe-ade0-8c3003d5e4bc/resourceGroups/PythonSDK/providers/Microsoft.MachineLearningServices/workspaces/pythonsdkworkspace/experiments/autoMLdemo1/runs/AutoML_84c472b3-a9af-4e84-b3cf-25c062742f5b\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>",
            "text/plain": "Run(Experiment: autoMLdemo1,\nId: AutoML_84c472b3-a9af-4e84-b3cf-25c062742f5b,\nType: automl,\nStatus: Preparing)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(remote_run).show()",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5eab8c6dfe0f46dfb2120334c6ecafe5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 's…"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#! pip install azureml.explain.model",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}